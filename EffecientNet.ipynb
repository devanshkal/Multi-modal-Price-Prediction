{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import timm  \n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981e69c5",
   "metadata": {},
   "source": [
    "For this project Effecientnet_b0 has been used as it is light-weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "624d6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4798c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa07bf9",
   "metadata": {},
   "source": [
    "Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8f36581",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"D:\\\\Amazon ML\\\\68e8d1d70b66d_student_resource\\\\student_resource\\\\dataset\\\\train.csv\")\n",
    "test_df = pd.read_csv(\"D:\\\\Amazon ML\\\\test1.csv\")\n",
    "\n",
    "assert all(col in train_df.columns for col in [\"sample_id\", \"catalog_content\", \"image_link\", \"price\"])\n",
    "assert all(col in test_df.columns for col in [\"sample_id\", \"catalog_content\", \"image_link\", \"price\"])\n",
    "\n",
    "train_df[\"price_per_unit\"] = train_df[\"price\"] / (train_df[\"catalog_content\"].str.len() + 1)\n",
    "test_df[\"price_per_unit\"] = test_df[\"price\"] / (test_df[\"catalog_content\"].str.len() + 1)\n",
    "\n",
    "train_df[\"text_length\"] = train_df[\"catalog_content\"].apply(lambda x: len(str(x)))\n",
    "test_df[\"text_length\"] = test_df[\"catalog_content\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "feature_cols = [\"price_per_unit\", \"text_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d212aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in feature_cols:\n",
    "    train_df[col] = pd.to_numeric(train_df[col], errors='coerce')\n",
    "    test_df[col] = pd.to_numeric(test_df[col], errors='coerce')\n",
    "\n",
    "train_df[feature_cols] = train_df[feature_cols].fillna(0)\n",
    "test_df[feature_cols] = test_df[feature_cols].fillna(0)\n",
    "\n",
    "# Split \n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "val_df[feature_cols] = scaler.transform(val_df[feature_cols])\n",
    "test_df[feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "# Force numeric dtype explicitly (fix for np.object_ error)\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors='coerce').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07c9edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price_per_unit    float32\n",
      "text_length       float32\n",
      "dtype: object\n",
      "price_per_unit    float32\n",
      "text_length       float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df[feature_cols].dtypes)\n",
    "print(test_df[feature_cols].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed0f9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame size (rows): 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test DataFrame size (rows): {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76320581",
   "metadata": {},
   "source": [
    "Transforming Images according to the ImageNet specifications and using reberta-base as a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1766b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriModalDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, feature_cols=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_url = row[\"image_link\"]\n",
    "        text = row[\"catalog_content\"]\n",
    "\n",
    "        #  Safely handle numeric features\n",
    "        feats_np = row[self.feature_cols].astype(np.float32).values\n",
    "        features = torch.tensor(feats_np, dtype=torch.float32)\n",
    "        price = torch.tensor(float(row[\"price\"]), dtype=torch.float32)\n",
    "\n",
    "        # Image \n",
    "        try:\n",
    "            response = requests.get(img_url, timeout=5)\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        except:\n",
    "            img = Image.new(\"RGB\", (224, 224), color=\"white\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Text\n",
    "        encoding = tokenizer(\n",
    "            text, truncation=True, padding='max_length',\n",
    "            max_length=128, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return img, encoding, features, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "495b85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TriModalDataset(train_df, image_transform, feature_cols)\n",
    "val_dataset = TriModalDataset(val_df, image_transform, feature_cols)\n",
    "test_dataset = TriModalDataset(test_df, image_transform, feature_cols)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriModalPricePredictor(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        # Image branch\n",
    "        self.img_model = efficientnet_b0(pretrained=True)\n",
    "        for param in self.img_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.img_model.classifier[1].in_features\n",
    "        self.img_model.classifier = nn.Identity()\n",
    "\n",
    "        # Text branch\n",
    "        self.text_model = AutoModel.from_pretrained(\"roberta-base\")\n",
    "        for param in self.text_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.text_fc = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Feature branch\n",
    "        self.feature_fc = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Combined head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs + 256 + 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, text_inputs, feats):\n",
    "        img_feat = self.img_model(img)\n",
    "        text_out = self.text_model(**{k: v.squeeze(1).to(device) for k, v in text_inputs.items()})\n",
    "        text_feat = text_out.last_hidden_state.mean(dim=1)\n",
    "        text_feat = self.text_fc(text_feat)\n",
    "        feat_feat = self.feature_fc(feats)\n",
    "        combined = torch.cat((img_feat, text_feat, feat_feat), dim=1)\n",
    "        return self.fc(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3566f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\devan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TriModalPricePredictor(feature_dim=len(feature_cols)).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c143d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for imgs, text_enc, feats, prices in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs, feats, prices = imgs.to(device), feats.to(device), prices.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs, text_enc, feats)\n",
    "        loss = criterion(outputs, prices)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, text_enc, feats, prices in val_loader:\n",
    "            imgs, feats, prices = imgs.to(device), feats.to(device), prices.to(device).unsqueeze(1)\n",
    "            outputs = model(imgs, text_enc, feats)\n",
    "            loss = criterion(outputs, prices)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Val Loss: {val_loss/len(val_loader):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ed738",
   "metadata": {},
   "source": [
    "Saving the model and the weights of the model in .pth format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781961e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"tri_modal_price_predictor.pth\")\n",
    "print(\"Model training complete and saved as 'tri_modal_price_predictor.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
